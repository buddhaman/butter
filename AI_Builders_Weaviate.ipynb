{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buddhaman/butter/blob/main/AI_Builders_Weaviate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb1537e6"
      },
      "source": [
        "# Using Weaviate with OpenAI vectorize module for Hybrid Search\n",
        "\n",
        "This notebook is prepared for a scenario where:\n",
        "* Your data is not vectorized\n",
        "* You want to run Hybrid Search ([learn more](https://weaviate.io/blog/hybrid-search-explained)) on your data\n",
        "* You want to use Weaviate with the OpenAI module ([text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai)), to generate vector embeddings for you.\n",
        "\n",
        "This notebook takes you through a simple flow to set up a Weaviate instance, connect to it (with OpenAI API key), configure data schema, import data (which will automatically generate vector embeddings for your data), and run hybrid search (mixing of vector and BM25 search).\n",
        "\n",
        "This is a common requirement for customers who want to store and search our embeddings with their own data in a secure environment to support production use cases such as chatbots, topic modelling and more.\n",
        "\n",
        "## What is Weaviate\n",
        "\n",
        "Weaviate is an open-source vector search engine that stores data objects together with their vectors. This allows for combining vector search with structured filtering.\n",
        "\n",
        "Weaviate uses KNN algorithms to create an vector-optimized index, which allows your queries to run extremely fast. Learn more [here](https://weaviate.io/blog/why-is-vector-search-so-fast).\n",
        "\n",
        "Weaviate let's you use your favorite ML-models, and scale seamlessly into billions of data objects.\n",
        "\n",
        "### Deployment options\n",
        "\n",
        "Whatever your scenario or production setup, Weaviate has an option for you. You can deploy Weaviate in the following setups:\n",
        "* Self-hosted – you can deploy Weaviate with docker locally, or any server you want.\n",
        "* SaaS – you can use [Weaviate Cloud Service (WCS)](https://console.weaviate.io/) to host your Weaviate instances.\n",
        "* Hybrid-Saas – you can deploy Weaviate in your own private Cloud Service \n",
        "\n",
        "### Programming languages\n",
        "\n",
        "Weaviate offers four [client libraries](https://weaviate.io/developers/weaviate/client-libraries), which allow you to communicate from your apps:\n",
        "* [Python](https://weaviate.io/developers/weaviate/client-libraries/python)\n",
        "* [JavaScript](https://weaviate.io/developers/weaviate/client-libraries/javascript)\n",
        "* [Java](https://weaviate.io/developers/weaviate/client-libraries/java)\n",
        "* [Go](https://weaviate.io/developers/weaviate/client-libraries/go)\n",
        "\n",
        "Additionally, Weavaite has a [REST layer](https://weaviate.io/developers/weaviate/api/rest/objects). Basically you can call Weaviate from any language that supports REST requests."
      ],
      "id": "cb1537e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45956173"
      },
      "source": [
        "## Demo Flow\n",
        "The demo flow is:\n",
        "- **Prerequisites Setup**: Create a Weaviate instance and install required libraries\n",
        "- **Connect**: Connect to your Weaviate instance \n",
        "- **Schema Configuration**: Configure the schema of your data\n",
        "    - *Note*: Here we can define which OpenAI Embedding Model to use\n",
        "    - *Note*: Here we can configure which properties to index on\n",
        "- **Import data**: Load a demo dataset and import it into Weaviate\n",
        "    - *Note*: The import process will automatically index your data - based on the configuration in the schema\n",
        "    - *Note*: You don't need to explicitly vectorize your data, Weaviate will communicate with OpenAI to do it for you.\n",
        "- **Run Queries**: Query \n",
        "    - *Note*: You don't need to explicitly vectorize your queries, Weaviate will communicate with OpenAI to do it for you.\n",
        "\n",
        "Once you've run through this notebook you should have a basic understanding of how to setup and use vector databases, and can move on to more complex use cases making use of our embeddings."
      ],
      "id": "45956173"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4a145e"
      },
      "source": [
        "## OpenAI Module in Weaviate\n",
        "All Weaviate instances come equiped with the [text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai) module.\n",
        "\n",
        "This module is responsible handling vectorization at import (or any CRUD operations) and when you run a query.\n",
        "\n",
        "### No need to manually vectorize data\n",
        "This is great news for you. With [text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai) you don't need to manually vectorize your data, as Weaviate will call OpenAI for you whenever necessary.\n",
        "\n",
        "All you need to do is:\n",
        "1. provide your OpenAI API Key – when you connected to the Weaviate Client\n",
        "2. define which OpenAI vectorizer to use in your Schema"
      ],
      "id": "2a4a145e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1a618c5"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before we start this project, we need setup the following:\n",
        "\n",
        "* create a `Weaviate` instance\n",
        "* install libraries\n",
        "    * `weaviate-client`\n",
        "    * `datasets`\n",
        "    * `apache-beam`\n",
        "* get your [OpenAI API key](https://beta.openai.com/account/api-keys)\n",
        "\n",
        "===========================================================\n",
        "### Create a Weaviate instance\n",
        "\n",
        "To create a Weaviate instance we have 2 options:\n",
        "\n",
        "1. (Recommended path) [Weaviate Cloud Service](https://console.weaviate.io/) – to host your Weaviate instance in the cloud. The free sandbox should be more than enough for this cookbook.\n",
        "2. Install and run Weaviate locally with Docker.\n",
        "\n",
        "#### Option 1 – WCS Installation Steps\n",
        "\n",
        "Use [Weaviate Cloud Service](https://console.weaviate.io/) (WCS) to create a free Weaviate cluster.\n",
        "1. create a free account and/or login to [WCS](https://console.weaviate.io/)\n",
        "2. create a `Weaviate Cluster` with the following settings:\n",
        "    * Sandbox: `Sandbox Free`\n",
        "    * Weaviate Version: Use default (latest)\n",
        "    * OIDC Authentication: `Disabled`\n",
        "3. your instance should be ready in a minute or two\n",
        "4. make a note of the `Cluster Id`. The link will take you to the full path of your cluster (you will need it later to connect to it). It should be something like: `https://your-project-name.weaviate.network` \n",
        "\n",
        "#### Option 2 – local Weaviate instance with Docker\n",
        "\n",
        "Install and run Weaviate locally with Docker.\n",
        "1. Download the [./docker-compose.yml](./docker-compose.yml) file\n",
        "2. Then open your terminal, navigate to where your docker-compose.yml folder, and start docker with: `docker-compose up -d`\n",
        "3. Once this is ready, your instance should be available at [http://localhost:8080](http://localhost:8080)\n",
        "\n",
        "Note. To shut down your docker instance you can call: `docker-compose down`\n",
        "\n",
        "##### Learn more\n",
        "To learn more, about using Weaviate with Docker see the [installation documentation](https://weaviate.io/developers/weaviate/installation/docker-compose)."
      ],
      "id": "f1a618c5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9babafe"
      },
      "source": [
        "===========================================================    \n",
        "## Install required libraries\n",
        "\n",
        "Before running this project make sure to have the following libraries:\n",
        "\n",
        "### Weaviate Python client\n",
        "\n",
        "The [Weaviate Python client](https://weaviate.io/developers/weaviate/client-libraries/python) allows you to communicate with your Weaviate instance from your Python project.\n",
        "\n",
        "### datasets & apache-beam\n",
        "\n",
        "To load sample data, you need the `datasets` library and its' dependency `apache-beam`."
      ],
      "id": "b9babafe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b04113f",
        "outputId": "c0cfcf78-b6df-463e-ca79-09493f8ee3a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting apache-beam==2.48.0\n",
            "  Downloading apache_beam-2.48.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod<2.0,>=1.7 (from apache-beam==2.48.0)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4.0 (from apache-beam==2.48.0)\n",
            "  Downloading orjson-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam==2.48.0)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam==2.48.0)\n",
            "  Downloading fastavro-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam==2.48.0)\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (1.54.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam==2.48.0)\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (0.21.0)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (1.22.4)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam==2.48.0)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam==2.48.0)\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (1.22.2)\n",
            "Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (2022.10.31)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (2.28.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (4.5.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam==2.48.0)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam==2.48.0) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam==2.48.0)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam==2.48.0) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam==2.48.0) (3.0.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam==2.48.0)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam==2.48.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam==2.48.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam==2.48.0) (2022.12.7)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.12.1.zip (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading multiprocess-0.70.12-py39-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.11.1-py39-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.6/126.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.11-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.10.zip (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.9.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: crcmod, dill, multiprocess, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=37090 sha256=389bb8081ca76cd0a6a84e7baec1480c13b1a38199b57f51090dd1b806270efa\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=147483b3afc6035e9c7e290813ed9bd620c65403fbdfd93f0e74ba0d18241ade\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for multiprocess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multiprocess: filename=multiprocess-0.70.9-py3-none-any.whl size=70934 sha256=aed95a91111e4896a3cd8117078fb306173ec42c0be6dc065825d50bb903b9d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/b9/ff/72cd56f34f0b3edde101afa3bf54c1ba85b771d51e7eaa7b03\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=8867aa203f003e63257bed39426e37d5f668fd76651ff45f82d09ed0662f465e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill multiprocess docopt\n",
            "Installing collected packages: docopt, crcmod, zstandard, xxhash, orjson, objsize, multidict, frozenlist, fasteners, fastavro, dnspython, dill, async-timeout, yarl, responses, pymongo, multiprocess, huggingface-hub, hdfs, aiosignal, apache-beam, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 apache-beam-2.48.0 async-timeout-4.0.2 crcmod-1.7 datasets-2.12.0 dill-0.3.1.1 dnspython-2.3.0 docopt-0.6.2 fastavro-1.7.4 fasteners-0.18 frozenlist-1.3.3 hdfs-2.7.0 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.9 objsize-0.6.1 orjson-3.9.0 pymongo-4.3.3 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2 zstandard-0.21.0\n",
            "env: OPENAI_API_KEY=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\n"
          ]
        }
      ],
      "source": [
        "# Install the Weaviate client for Python\n",
        "!pip install weaviate-client>=3.11.0\n",
        "\n",
        "# Install datasets and apache-beam to load the sample datasets\n",
        "!pip install datasets apache-beam==2.48.0\n",
        "\n",
        "# Set OPENAI_API_KEY\n",
        "%env OPENAI_API_KEY=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"
      ],
      "id": "2b04113f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CNwR-KQGpGj",
        "outputId": "87878be6-e609-45df-d6ca-6364c2994c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dill==0.3.6\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess==0.70.14\n",
            "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "Installing collected packages: dill, multiprocess\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.1.1\n",
            "    Uninstalling dill-0.3.1.1:\n",
            "      Successfully uninstalled dill-0.3.1.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.9\n",
            "    Uninstalling multiprocess-0.70.9:\n",
            "      Successfully uninstalled multiprocess-0.70.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "apache-beam 2.48.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dill-0.3.6 multiprocess-0.70.14\n"
          ]
        }
      ],
      "source": [
        "!pip install dill==0.3.6 multiprocess==0.70.14"
      ],
      "id": "8CNwR-KQGpGj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36fe86f4"
      },
      "source": [
        "===========================================================\n",
        "## Prepare your OpenAI API key\n",
        "\n",
        "The `OpenAI API key` is used for vectorization of your data at import, and for queries.\n",
        "\n",
        "If you don't have an OpenAI API key, you can get one from [https://beta.openai.com/account/api-keys](https://beta.openai.com/account/api-keys).\n",
        "\n",
        "Once you get your key, please add it to your environment variables as `OPENAI_API_KEY`."
      ],
      "id": "36fe86f4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88be138c",
        "outputId": "84c9ba29-3796-45a5-824b-bbb1c3240fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY is ready\n"
          ]
        }
      ],
      "source": [
        "# Test that your OpenAI API key is correctly set as an environment variable\n",
        "# Note. if you run this notebook locally, you will need to reload your terminal and the notebook for the env variables to be live.\n",
        "import os\n",
        "\n",
        "# Note. alternatively you can set a temporary env variable like this:\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-key-goes-here'\n",
        "\n",
        "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
        "    print (\"OPENAI_API_KEY is ready\")\n",
        "else:\n",
        "    print (\"OPENAI_API_KEY environment variable not found\")"
      ],
      "id": "88be138c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91df4d5b"
      },
      "source": [
        "## Connect to your Weaviate instance\n",
        "\n",
        "In this section, we will:\n",
        "\n",
        "1. test env variable `OPENAI_API_KEY` – **make sure** you completed the step in [#Prepare-your-OpenAI-API-key](#Prepare-your-OpenAI-API-key)\n",
        "2. connect to your Weaviate your `OpenAI API Key`\n",
        "3. and test the client connection\n",
        "\n",
        "### The client \n",
        "\n",
        "After this step, the `client` object will be used to perform all Weaviate-related operations."
      ],
      "id": "91df4d5b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc662c1b",
        "outputId": "ecb49b5a-39b2-408c-d763-ba31e754bf12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import weaviate\n",
        "import os\n",
        "\n",
        "client = weaviate.Client(\n",
        "  url=\"https://thwd4k3s4mhnihmi2yvzg.gcp-a.weaviate.cloud\",  # URL of your Weaviate instance\n",
        "  auth_client_secret=weaviate.AuthApiKey(api_key=\"BZ3Bl66skCU51TJ8WlUv1XrZjzB2Eee6ks7D\"), # (Optional) If the Weaviate instance requires authentication\n",
        "  additional_headers={\n",
        "    \"X-OpenAI-Api-Key\": \"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\", # Replace with your OpenAI key\n",
        "  }\n",
        ")\n",
        "# Check if your instance is live and ready\n",
        "# This should return `True`\n",
        "client.is_ready()"
      ],
      "id": "cc662c1b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d3dac3c"
      },
      "source": [
        "# Schema\n",
        "\n",
        "In this section, we will:\n",
        "1. configure the data schema for your data\n",
        "2. select OpenAI module\n",
        "\n",
        "> This is the second and final step, which requires OpenAI specific configuration.\n",
        "> After this step, the rest of instructions wlll only touch on Weaviate, as the OpenAI tasks will be handled automatically.\n",
        "\n",
        "\n",
        "## What is a schema\n",
        "\n",
        "In Weaviate you create __schemas__ to capture each of the entities you will be searching.\n",
        "\n",
        "A schema is how you tell Weaviate:\n",
        "* what embedding model should be used to vectorize the data\n",
        "* what your data is made of (property names and types)\n",
        "* which properties should be vectorized and indexed\n",
        "\n",
        "In this cookbook we will use a dataset for `Articles`, which contains:\n",
        "* `title`\n",
        "* `content`\n",
        "* `url`\n",
        "\n",
        "We want to vectorize `title` and `content`, but not the `url`.\n",
        "\n",
        "To vectorize and query the data, we will use `text-embedding-ada-002`."
      ],
      "id": "7d3dac3c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f894b911",
        "outputId": "c36ace52-1f61-402e-8d54-3df4d745e128",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classes': [{'class': 'Article',\n",
              "   'description': 'A collection of articles',\n",
              "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
              "    'cleanupIntervalSeconds': 60,\n",
              "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
              "   'moduleConfig': {'text2vec-openai': {'model': 'ada',\n",
              "     'modelVersion': '002',\n",
              "     'type': 'text',\n",
              "     'vectorizeClassName': True}},\n",
              "   'properties': [{'dataType': ['text'],\n",
              "     'description': 'Title of the article',\n",
              "     'indexFilterable': True,\n",
              "     'indexSearchable': True,\n",
              "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
              "       'vectorizePropertyName': False}},\n",
              "     'name': 'title',\n",
              "     'tokenization': 'whitespace'},\n",
              "    {'dataType': ['text'],\n",
              "     'description': 'Contents of the article',\n",
              "     'indexFilterable': True,\n",
              "     'indexSearchable': True,\n",
              "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
              "       'vectorizePropertyName': False}},\n",
              "     'name': 'content',\n",
              "     'tokenization': 'word'},\n",
              "    {'dataType': ['text'],\n",
              "     'description': 'URL to the article',\n",
              "     'indexFilterable': True,\n",
              "     'indexSearchable': True,\n",
              "     'moduleConfig': {'text2vec-openai': {'skip': True,\n",
              "       'vectorizePropertyName': False}},\n",
              "     'name': 'url',\n",
              "     'tokenization': 'whitespace'}],\n",
              "   'replicationConfig': {'factor': 1},\n",
              "   'shardingConfig': {'virtualPerPhysical': 128,\n",
              "    'desiredCount': 1,\n",
              "    'actualCount': 1,\n",
              "    'desiredVirtualCount': 128,\n",
              "    'actualVirtualCount': 128,\n",
              "    'key': '_id',\n",
              "    'strategy': 'hash',\n",
              "    'function': 'murmur3'},\n",
              "   'vectorIndexConfig': {'skip': False,\n",
              "    'cleanupIntervalSeconds': 300,\n",
              "    'maxConnections': 64,\n",
              "    'efConstruction': 128,\n",
              "    'ef': -1,\n",
              "    'dynamicEfMin': 100,\n",
              "    'dynamicEfMax': 500,\n",
              "    'dynamicEfFactor': 8,\n",
              "    'vectorCacheMaxObjects': 1000000000000,\n",
              "    'flatSearchCutoff': 40000,\n",
              "    'distance': 'cosine',\n",
              "    'pq': {'enabled': False,\n",
              "     'bitCompression': False,\n",
              "     'segments': 0,\n",
              "     'centroids': 256,\n",
              "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
              "   'vectorIndexType': 'hnsw',\n",
              "   'vectorizer': 'text2vec-openai'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Clear up the schema, so that we can recreate it\n",
        "client.schema.delete_all()\n",
        "client.schema.get()\n",
        "\n",
        "# Define the Schema object to use `text-embedding-ada-002` on `title` and `content`, but skip it for `url`\n",
        "article_schema = {\n",
        "    \"class\": \"Article\",\n",
        "    \"description\": \"A collection of articles\",\n",
        "    \"vectorizer\": \"text2vec-openai\",\n",
        "    \"moduleConfig\": {\n",
        "        \"text2vec-openai\": {\n",
        "          \"model\": \"ada\",\n",
        "          \"modelVersion\": \"002\",\n",
        "          \"type\": \"text\"\n",
        "        }\n",
        "    },\n",
        "    \"properties\": [{\n",
        "        \"name\": \"title\",\n",
        "        \"description\": \"Title of the article\",\n",
        "        \"dataType\": [\"string\"]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"content\",\n",
        "        \"description\": \"Contents of the article\",\n",
        "        \"dataType\": [\"text\"]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"url\",\n",
        "        \"description\": \"URL to the article\",\n",
        "        \"dataType\": [\"string\"],\n",
        "        \"moduleConfig\": { \"text2vec-openai\": { \"skip\": True } }\n",
        "    }]\n",
        "}\n",
        "\n",
        "# add the Article schema\n",
        "client.schema.create_class(article_schema)\n",
        "\n",
        "# get the schema to make sure it worked\n",
        "client.schema.get()"
      ],
      "id": "f894b911"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5d9d2e1"
      },
      "source": [
        "## Import data\n",
        "\n",
        "In this section we will:\n",
        "1. load the Simple Wikipedia dataset\n",
        "2. configure Weaviate Batch import (to make the import more efficient)\n",
        "3. import the data into Weaviate\n",
        "\n",
        "> Note: <br/>\n",
        "> Like mentioned before. We don't need to manually vectorize the data.<br/>\n",
        "> The [text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai) module will take care of that."
      ],
      "id": "e5d9d2e1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8k283FTCJMT",
        "outputId": "d67cb65e-660c-47e5-d1ee-6772a41fd2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.28.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ],
      "id": "b8k283FTCJMT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80nBHpmoEDnU"
      },
      "outputs": [],
      "source": [
        "!pip show dill"
      ],
      "id": "80nBHpmoEDnU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEJC15uVFFIB"
      },
      "outputs": [],
      "source": [
        "!pip show multiprocess"
      ],
      "id": "pEJC15uVFFIB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHUxbXrCCLVX"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ],
      "id": "aHUxbXrCCLVX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc3efadd"
      },
      "outputs": [],
      "source": [
        "from typing import List, Iterator\n",
        "\n",
        "# We'll use the datasets library to pull the Simple Wikipedia dataset for embedding\n",
        "dataset = list(load_dataset(\"amazon_us_reviews\", \"Apparel_v1_00\")[\"train\"])\n",
        "\n",
        "# For testing, limited to 2.5k articles for demo purposes\n",
        "dataset = dataset[:2_500]\n",
        "\n",
        "# Limited to 25k articles for larger demo purposes\n",
        "# dataset = dataset[:25_000]\n",
        "\n",
        "# for free OpenAI acounts, you can use 50 objects\n",
        "# dataset = dataset[:50]"
      ],
      "id": "fc3efadd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5044da96"
      },
      "outputs": [],
      "source": [
        "### Step 2 - configure Weaviate Batch, with\n",
        "# - starting batch size of 100\n",
        "# - dynamically increase/decrease based on performance\n",
        "# - add timeout retries if something goes wrong\n",
        "\n",
        "client.batch.configure(\n",
        "    batch_size=250, \n",
        "    dynamic=True,\n",
        "    timeout_retries=3,\n",
        "#   callback=None,\n",
        ")"
      ],
      "id": "5044da96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15db8380"
      },
      "outputs": [],
      "source": [
        "### Step 3 - import data\n",
        "\n",
        "print(\"Importing Articles\")\n",
        "\n",
        "counter=0\n",
        "\n",
        "with client.batch as batch:\n",
        "    for article in dataset:\n",
        "        if (counter %10 == 0):\n",
        "            print(f\"Import {counter} / {len(dataset)} \")\n",
        "\n",
        "        properties = {\n",
        "            \"title\": article[\"title\"],\n",
        "            \"content\": article[\"text\"],\n",
        "            \"url\": article[\"url\"]\n",
        "        }\n",
        "        \n",
        "        batch.add_data_object(properties, \"Article\")\n",
        "        counter = counter+1\n",
        "\n",
        "print(\"Importing Articles complete\")       "
      ],
      "id": "15db8380"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3658693c"
      },
      "outputs": [],
      "source": [
        "# Test that all data has loaded – get object count\n",
        "result = (\n",
        "    client.query.aggregate(\"Article\")\n",
        "    .with_fields(\"meta { count }\")\n",
        "    .do()\n",
        ")\n",
        "print(\"Object count: \", result[\"data\"][\"Aggregate\"][\"Article\"], \"\\n\")"
      ],
      "id": "3658693c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d791186"
      },
      "outputs": [],
      "source": [
        "# Test one article has worked by checking one object\n",
        "test_article = (\n",
        "    client.query\n",
        "    .get(\"Article\", [\"title\", \"url\", \"content\"])\n",
        "    .with_limit(1)\n",
        "    .do()\n",
        ")[\"data\"][\"Get\"][\"Article\"][0]\n",
        "\n",
        "print(test_article['title'])\n",
        "print(test_article['url'])\n",
        "print(test_article['content'])"
      ],
      "id": "0d791186"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46050ca9"
      },
      "source": [
        "### Search Data\n",
        "\n",
        "As above, we'll fire some queries at our new Index and get back results based on the closeness to our existing vectors\n",
        "\n",
        "Learn more about the `alpha` setting [here](https://weaviate.io/developers/weaviate/api/graphql/vector-search-parameters#hybrid)"
      ],
      "id": "46050ca9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b044aa93"
      },
      "outputs": [],
      "source": [
        "def hybrid_query_weaviate(query, collection_name, alpha_val):\n",
        "    \n",
        "    nearText = {\n",
        "        \"concepts\": [query],\n",
        "        \"distance\": 0.7,\n",
        "    }\n",
        "\n",
        "    properties = [\n",
        "        \"title\", \"content\", \"url\",\n",
        "        \"_additional { score }\"\n",
        "    ]\n",
        "\n",
        "    result = (\n",
        "        client.query\n",
        "        .get(collection_name, properties)\n",
        "        .with_hybrid(nearText, alpha=alpha_val)\n",
        "        .with_limit(10)\n",
        "        .do()\n",
        "    )\n",
        "    \n",
        "    # Check for errors\n",
        "    if (\"errors\" in result):\n",
        "        print (\"\\033[91mYou probably have run out of OpenAI API calls for the current minute – the limit is set at 60 per minute.\")\n",
        "        raise Exception(result[\"errors\"][0]['message'])\n",
        "    \n",
        "    print (f\"Objects returned: {len(result)}\")\n",
        "    \n",
        "    return result[\"data\"][\"Get\"][collection_name]"
      ],
      "id": "b044aa93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e2025f6"
      },
      "outputs": [],
      "source": [
        "query_result = hybrid_query_weaviate(\"modern art in Europe\", \"Article\", 0.5)\n",
        "\n",
        "for i, article in enumerate(query_result):\n",
        "    print(f\"{i+1}. { article['title']} (Score: {article['_additional']['score']})\")"
      ],
      "id": "7e2025f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93c4a696"
      },
      "outputs": [],
      "source": [
        "query_result = hybrid_query_weaviate(\"Famous battles in Scottish history\", \"Article\", 0.5)\n",
        "\n",
        "for i, article in enumerate(query_result):\n",
        "    print(f\"{i+1}. { article['title']} (Score: {article['_additional']['score']})\")"
      ],
      "id": "93c4a696"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2007be48"
      },
      "source": [
        "Thanks for following along, you're now equipped to set up your own vector databases and use embeddings to do all kinds of cool things - enjoy! For more complex use cases please continue to work through other cookbook examples in this repo."
      ],
      "id": "2007be48"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}